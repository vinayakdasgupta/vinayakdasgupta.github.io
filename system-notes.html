<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Vinayak Das Gupta – Writing</title>
  <link rel="stylesheet" href="/assets/css/style.css">
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@400;600&display=swap" rel="stylesheet">
</head>
<body>
  <header>
    <nav>
      <a href="index.html">Home</a>
      <a href="projects.html">Projects</a>
      <a href="writing.html">Writing</a>
      <a href="cv.html">CV</a>
      <a href="contact.html">Contact</a>
    </nav>
  </header>

  <main class="content">
    <h1>System notes</h1>

    <section class="blog-post">
        <h2>800 ≠ 200: The Panic and the Log Line</h2>
        <p>It began, as these things often do, with a log file. It was followed by a panic attack.</p>
        <p>Late one evening, I was going over training logs for <em>anvay</em> — my Bengali topic modelling tool — when I saw this line:<br>
        <code>merging changes from 200 documents into a model of 800 documents</code></p>
        <p>Something inside me stopped. I had claimed, quite confidently, in a paper submitted to a reputed peer-reviewed journal that <em>anvay</em> could process up to 800 documents. That it did so with a large vocabulary, over a million tokens, and in 62 seconds. Just to put it in context, the Gensim library (on which <em>anvay</em> is developed), out of the box, is about six times slower. Mallet (another popular topic modelling tool) is much, much slower. So, this was important to me. I had timed it. I had tested it. I had written about it. But this line suggested that something else was happening. That Gensim, the library handling the topic model, was only using 200 documents. And worse, it wasn't raising an error. It was merging them. I was caught off-guard.</p>
        <p>This wasn’t just a bug. If true, it meant that everything I had claimed, all the benchmarks, all the performance tests, all the carefully worded assertions about scalability and robustness was wrong.</p>
        <p>The panic that followed was entirely disproportionate and also completely familiar. A kind of tight, academic horror. Not because a tool might be broken, but because a mistake might have already been published. Because the act of writing had already fossilised something I might now have to recant.</p>
        <p>I went line by line through the code. I turned off all filters. I rechecked the tokenizer. I reran the same data under different configurations. Still: 200. I began rehearsing how I might write back to the editors. <br>
        <em>‘I regret to inform you that the benchmarks were inaccurate...’</em></p>
        <p>The turning point came, strangely enough, not from insight, but from exhaustion. I reduced the <code>chunksize</code> parameter — the number of documents Gensim processes in a single batch during training — from 200 to 64.</p>
        <p>The log now read:<br>
        <code>merging changes from 64 documents into a model of 800 documents</code></p>
        <p>That was it. That was all. The first number was the current chunk. The second was the total model. Gensim had never truncated anything. The system had always worked.</p>
        <p>The line was never proof of error. It was evidence of function. I simply didn't know how to read it.</p>
        <p>The <code>chunksize</code> parameter in Gensim’s LDA controls how many documents are processed in each batch during training. This is clear enough. What was unclear to me is this: when you see a log like “merging changes from 200 documents into a model of 800 documents,” it doesn’t mean only 200 documents were used. It means that Gensim has just processed one batch (of 200) and is now integrating that batch’s updates into the full 800-document model. The phrase reflects the incremental, online nature of training, where the global model is gradually updated from successive chunks. It’s a normal part of how <code>LdaMulticore</code> handles scalability and memory efficiency. I am still unsure if that line is the best way to communicate this.</p>
        <p>This would be a minor story if not for what it revealed about the emotional structure of academic work. The fear was not technical. It was social. It was the fear of being wrong in public. Of having claimed something and having it quietly unravel.</p>
        <p>There is a pressure in scholarly software to be unimpeachable. To be right, and to be right early. To anticipate every misunderstanding, every failure mode. But code isn’t like that. Neither is writing.</p>
        <p>What I had was a system that worked. What I lacked, for a moment, was the confidence to believe that I hadn’t faked it.</p>
        <p>What held up, in the end, was not just the pipeline. It was the process. <br>
        <em>anvay</em> wasn’t broken; I just needed to trust that I had done the work in the right way.</p>
      </section>
      
    
    <hr>
    
    <section class="blog-post">
        <h2>When the System Surprises You</h2>
        <h4>On emergence, authorship, and the quiet astonishment of generative art</h4>
      
        <p>The study of generative art arrived in my work through teaching. While designing a postgraduate course on art and technology, I found myself confronted with a curious category of works: visual artefacts generated not by hand, but by system. These were unmistakably aesthetic, sometimes astonishingly so.</p>
      
        <p>The question I began with was deceptively simple: how do we study art that was not composed in the traditional sense, but emerged?</p>
      
        <p>Generative art, in one of its more widely accepted definitions, is art in which an autonomous system contributes materially to the output. It is not random, nor is it fully authored. It sits somewhere in between. The artist constructs the constraints, sets the process in motion, but the final form is unknown until it appears. This unknowability — what systems theorists call emergence — is not a failure of control. It is the very condition of generativity.</p>
      
        <p>Let me make this concrete.</p>
      
        <p>I once wrote a program to generate an image I titled <em>Barcelona</em>. It is built on a system of Voronoi tessellations. The visual outcome, an abstract composition of coloured circles and black rectangles, is produced by distributing 6000 points across a canvas. These points are not randomly scattered, but weighted by the brightness values of a hidden reference image. Five colours are used. Each run of the program creates a new composition. No two are alike.</p>
      
        <p>To an external observer, <em>Barcelona</em> might seem composed, even calculated. But I know better. I know that while I chose the colours, the number of points, and the structure of the algorithm, I cannot determine the final image. I can control the rules, not the result.</p>
      
        <p>This is emergence. And it manifests in two distinct modes.</p>

        <div style="text-align: center; margin-bottom: 1.5rem;">
            <img src="/assets/img/barcelona.PNG" alt="Barcelona - generative artwork" style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 4px; background: #f9f9f9;">
        </div>
      
        <p>In one, <strong>objective emergence</strong>, we acknowledge the limits of our predictive power. The system behaves in ways that cannot be reduced to simpler descriptions. The only way to know what it will do is to run it. This is a familiar intuition to anyone who has worked in data analysis: simulation becomes epistemology.</p>
      
        <p>In the other, <strong>subjective emergence</strong>, the system surprises even when we understand it completely. It is not our ignorance that produces mystery, but the aesthetics of perception. We are startled by what we already know.</p>
      
        <p>Both modes challenge traditional ideas of authorship. They also challenge how we evaluate art. If each run of the algorithm generates a different output, which one is the work? If surprise is engineered, does it lose its value?</p>
      
        <p>Perhaps most provocatively, emergence invites us to reconsider the role of the artist. The value of a generative work lies not in its uniqueness, but in its capacity to generate uniqueness within constraint. The artist becomes less a composer and more a constructor of possibility.</p>
      
        <p>This, too, has implications for how we study such works. To appreciate a generative piece is not merely to look at it, but to understand the system that gave rise to it. In that sense, the aesthetics of generative art are inseparable from its mechanics. The code is not behind the art: it <em>is</em> the art.</p>
      
        <p>Some critics have argued that such works lack soul. That if emotion is absent at the point of generation, it cannot be recovered by the viewer. But this misunderstands the nature of system-based creation. Every line of code is a decision, every constraint a gesture. The emergence of form does not negate its meaning. It refracts it.</p>
      
        <p>The ink painting left to bleed. The salt print slowly darkening. The algorithm letting go. These are not separate categories. They are all moments where something more is produced than what was put in.</p>
      
        <p>And if we are moved by what we see, does it really matter how it was made?</p>
      </section>
      
    
    <hr>
    
    <section class="blog-post">
        <h2>Digital Humanities Didn’t Begin with the Computer</h2>
      
        <p>Every discipline has its origin myth. For Digital Humanities, it is often the story of Father Roberto Busa and the <em>Index Thomisticus</em>: a monumental mid-20th century effort to encode the works of Thomas Aquinas using IBM punch cards. It is an impressive origin story that really writes itself: how a clergyman met and tamed the machine. It is the story many of us learn in the first decade of the 21st century.</p>
      
        <p>But what if this isn’t where it began? What if tying the origins of a field to a machine — a particular instantiation of technology at a particular moment — obscures something older, more essential?</p>
      
        <p>My concern is not with the figure of Busa, but with what his positioning implies: that Digital Humanities is defined by its relationship to the modern computer. That computation and the computer are one and the same. This, I would argue, is both historically and conceptually misleading.</p>
      
        <p>Computation precedes the computer. Long before circuits and silicon, there were systems of reckoning. The abacus, Napier’s bones, Leibniz’s calculator, Babbage’s Analytical Engine — each a step in a lineage of mathematical imagination. The computer is not the origin of computation; it is one of its many manifestations. If we think of Digital Humanities as computationally inflected humanistic inquiry, then its history cannot begin with the mid-twentieth century. It must begin much earlier, in the moments when pattern, structure, and formal constraint became tools for thinking in the humanities.</p>
      
        <p>Take literature, for instance. The claim that literature resists mathematical thinking — that it is unrepeatable, affective, beyond system — is, I suspect, more myth than fact. Literature has long been shaped by form, rule, and design. The sonnet is a constraint. So is tragedy in five acts. So is the rhyme scheme of Dante’s <em>Divine Comedy</em>. Mathematical imagination is not an intrusion into literature; it is one of its substrates.</p>
      
        <p>Consider Vladimir Propp’s <em>Morphology of the Folktale</em> (1928). From a modest corpus of one hundred Russian fairy tales, Propp extracted a system of 31 functions, basic narrative moves that always occur in a fixed order. It is a kind of proto-algorithmic thinking. A recognition that stories are not infinite, but patterned. That imagination has structure.</p>
      
        <p>Or consider the Oulipo group, founded in the 1960s, a gathering of writers and mathematicians who used constraint as a source of creative energy. For them, the literary work was a combinatorial engine. Form came first. Meaning would follow, if it could.</p>
      
        <p>If this is computation — understood as rule-based generation and systemic variation — then surely it existed long before the computer. And if Digital Humanities is about these modes of inquiry, then it too predates its name.</p>
      
        <p><strong>So why does this matter?</strong></p>
      
        <p>Because origin stories shape expectations. When we tie a field to a specific technology, we make it vulnerable to that technology’s limits, its obsolescence, its market logics. We confuse the machine with the method. We risk reducing thought to tool-use.</p>
      
        <p>We also risk absurdity. If the presence of a computer defines Digital Humanities, then every action on a device — from writing a document to checking email — becomes a DH act. This is clearly untenable. Not everything done on a computer is Digital Humanities. Nor must Digital Humanities always involve a computer.</p>
      
        <p>What matters is the disposition. A willingness to think structurally, to formalise ambiguity, to trace patterns in what seems singular. To ask: what else might this text or this image or this object reveal if we look at it sideways?</p>
      
        <p>And here, the computer is simply one more lens. Powerful, yes. But not foundational.</p>
      
        <p>I have no desire to unseat Busa. His work was remarkable, and symbolic in all the right ways. But perhaps it is time to write a different prelude to the field — one that begins not with machines, but with a form of thought. Not with a moment, but with a method.</p>
      
        <p><strong>Digital Humanities, then, is not defined by the digital. It is animated by the mathematical. And mathematics, quietly, but intently, has always been part of the humanities.</strong></p>
      </section>


<section class="blog-post">
  <h2>The Photograph Already Exists</h2>

  <p>On my first day in Dublin, I walked into the front square at Trinity College. I had barely crossed the threshold when I saw the bell tower. It stands in the centre of the square, tall and symmetrical, with enough architectural confidence to anchor a campus. I had seen it before. On postcards, university websites, travel blogs. I knew exactly what it looked like.</p>

  <p>Still, I took a photograph.</p>

  <p>Not just one. I circled around it, found the angle where the arch cut against the sky, waited for tourists to move, pressed the shutter. I wasn’t alone. Nearly everyone around me was doing the same.</p>

  <p>This is not a complaint. I don’t think we take photographs because we want to possess the image. We take them because we want to affirm the moment. To say: I was here. I stood at this distance, in this light, under this particular version of the sky.</p>

  <p>The photograph already exists. But this one is mine.</p>

  <p>That difference, small as it is, speaks to something fundamental about how digital photography has reshaped our sense of time. The image is no longer a record of what was seen. It is a mark of presence. It performs the moment, rather than preserving it.</p>

  <p>There’s no longer any scarcity. We don’t ration film. We don’t pause before each frame. We take five versions of the same shot, just in case. And still, we worry we missed something. The more we can capture, the more we feel the need to.</p>

  <p>If the printed photograph was once something to be returned to, a fragment of memory retrieved from a drawer, then the digital photograph is something else. It exists in a kind of forward motion. It is not about reflection. It is about immediate confirmation.</p>

  <p>Here I am.</p>

  <p>But now we find ourselves in an even stranger situation. We no longer need to be there at all.</p>

  <p>It began quietly. A finger in the frame could be erased. A stranger in the background, brushed out. A group photo where someone blinked could be fixed so that everyone smiled, everyone’s eyes open, no one distracted. The photograph, once stubborn and contingent, became negotiable.</p>

  <p>We started to remove the moment’s interruptions. The awkwardness. The slant. The wind in the hair. The thing that made the image feel real — that small resistance — became a flaw to be corrected.</p>

  <p>And then something else happened. We began to collapse time. Instead of choosing the best shot, we let the system merge them. A dozen photographs, taken in quick succession, layered into one. The clearest face from frame three, the sharpest hand from frame seven, the softest light from frame nine. We no longer remembered which one was the original. Or if that distinction even mattered.</p>

  <p>The synthetic photograph doesn’t just alter the image. It erases the moment. What we’re left with is a kind of perfect average — all memory compressed into a single, frictionless record.</p>

  <p>But the record is no longer of <em>what was</em>. It is of what <em>should have been</em>.</p>

  <p>From there, it is a short distance to fabrication. A sunset that never happened. A trip we never took. A street that no longer exists, reconstructed from old maps and good guesses. Faces that have never been seen, belonging to people who have never lived.</p>

  <p>The image detaches itself from the event. It becomes its own event.</p>

  <p>The question is no longer “Why photograph what already exists?” but “Why photograph at all?” Why stand still, in imperfect light, if the system can make it better, cleaner, more complete?</p>

  <p>We can summon images now. We don’t have to witness them.</p>

  <p>And yet the compulsion remains.</p>

  <p>We still lift the camera. We still point. We still say: that.</p>

  <p>There is something in the act that resists replacement. Not because it is sacred, but because it is situated. Because it insists on the body — on presence, on friction, on the missed shot. The photograph, however corrected, still bears the trace of standing there. Of choosing a frame. Of accepting that something was always just outside it.</p>

  <p>Maybe synthetic images will learn to mimic that trace. Maybe they already do.</p>

  <p>But I still believe in the version where the light hit wrong, and I took it anyway.</p>

  <p>I was there.<br>
  And this version of the bell tower — this particular angle, this particular day — did not exist until I made it.</p>
</section>

      
  </main>

  <footer>
    <p>&copy; 2024 Vinayak Das Gupta. All rights reserved.</p>
  </footer>
</body>
</html>